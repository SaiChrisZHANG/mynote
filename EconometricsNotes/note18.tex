\documentclass[twoside]{article}
\input{settings.tex}

\begin{document}
\lecture{18}{Eigenvalue and Spike Models}{}{Sai Zhang}{.}{The note is built on Prof. \hyperlink{http://faculty.marshall.usc.edu/jinchi-lv/}{Jinchi Lv}'s lectures of the course at USC, DSO 607, High-Dimensional Statistics and Big Data Problems.}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

\section{Motivation}
Consider $n$ independent observations $\mathbf{X}_i\in \mathbb{R}^p$ drawn from a $\mathcal{N}(\mathbf{0},\boldsymbol{\Sigma})$, then the covariance can be decomposed into 2 parts, white noise and low rank
\begin{align*}
    \boldsymbol{\Sigma} = \mathrm{Cov}(\mathbf{X}_i) = \mathbf{I} + \sum^M_{k=1}\theta_k \nu_k\nu'_k =\boldsymbol{\Sigma}_0 + \boldsymbol{\Phi}
\end{align*}
where $M$ denotes the \myhl[myblue]{\textbf{number of spikes}} in the distribution of eigenvalues. The idea is: spikes deviate from a reference model along a \textbf{\underline{small fixed number}} of unknown directions. If $\boldsymbol{\Phi}=\mathbf{0}$, then none of the sample eigenvalues is separated from the bulk.

\paragraph*{Why a spike model is interesting?} A spike model can help determine the latent dimension of the data, some examples being
\begin{itemize}
    \item Principal component analysis (PCA): spikes are related to the directions of the most variations of the data, i.e., the principal components
    \item Clustering model: $M$ spikes is equivalent to $M+1$ clusters
    \item Economic significance: $M$ is related to the number of factor loadings
\end{itemize}

Then the question is threefold: 
\begin{itemize}
    \item[-] How to determine $M$
    \item[-] How to estimate $\nu_k$
    \item[-] How to test $\theta_k$
\end{itemize}

Under rank one alternative, we would like to test the hypothesis
$$ the
H_1: \boldsymbol{\Sigma} = \mathbf{I}_p+ \theta\boldsymbol{\nu}\boldsymbol{\nu}', \theta>0
$$
against the null
\begin{align*}
    H_0 &: \boldsymbol{\Sigma}= \mathbf{I}_p
\end{align*}
with the key assumptions:
\begin{itemize}
    \item[A1] Gaussian error
    \item[A2] large $p$: $p\leq n$ but allows $p/n \rightarrow \gamma \in (0,1)$ 
\end{itemize}
Under these assumptions, for the $n\times p$ data matrix $\mathbf{X} = \begin{pmatrix}
    \mathbf{X}'_1 &\cdots & \mathbf{X}'_n
\end{pmatrix}'$, $\mathbf{X}'\mathbf{X}$ has a $p-$dimensional \myhl[myblue]{\textbf{Wishart} distribution $W_p(n,\boldsymbol{\Sigma})$} with the degree of freedom $n$ and covariance matrix $\boldsymbol{\Sigma}$, which is a \textit{random matrix}.

If $\mathbf{Y} = \mathbf{M} + \mathbf{X}$, that is, the sum of the \textit{random matrix} $\mathbf{X}$ and a \textit{deterministic matrix} $\mathbf{M}$ (also $n\times p$)

\newpage
\bibliographystyle{plainnat}
\bibliography{ref.bib}

\end{document}