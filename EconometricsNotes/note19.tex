\documentclass[twoside]{article}
\input{settings.tex}

\begin{document}
\lecture{19}{Community Detection}{}{Sai Zhang}{.}{The note is built on Prof. \hyperlink{http://faculty.marshall.usc.edu/jinchi-lv/}{Jinchi Lv}'s lectures of the course at USC, DSO 607, High-Dimensional Statistics and Big Data Problems.}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

\section{Stochastic Block Model (Abbe et al., 2015)}

Consider an undirected graph $G$, with nodes $V$ and edges $E$. Let 
    \begin{itemize}
        \item $n$ be a positive integer: the number of \textbf{vertices}
        \item $k$ be a positive integer: the number of \textbf{communities}
        \item $p=\left(p_1,\cdots,p_k\right)$ be a probability vector on $\left\{ 1,\cdots,k \right\} \coloneq [k]$: the \textbf{prior} on the $k$ communities
        \item $\mathbf{W}$ be a $k\times k$ symmetric matrix with entries $ W_{ij}\in [0,1]$: the matrix of \textbf{connectivity probabilities}
    \end{itemize}
then we have
\begin{definition}{Stochastic Block Model}{stoch_block_model}
    The pair $(\mathbf{X},G)$ is drawn under $SBM(n,p,\mathbf{W})$ if $\mathbf{X}$ is an $n$ dimensional random vector with i.i.d. components distributed under $p$, and $G$ is an $n-$vertex simple graph 
    where vertices $i$ and $j$ are connected with probability $W_{X_i,X_j}$, \myhl[myred]{\textbf{independently}} of other pairs of vertices. And the \textbf{community} sets can be defined by 
    \begin{equation*}
        \Omega_i = \Omega_i(\mathbf{X}) \coloneq \left\{ v\in [n]: X_v=i \right\}, i\in [k]
    \end{equation*}
\end{definition}
Immediately, we can define the symmetry of SBM as:
\begin{definition}{Symmetric SBM}{symmetric_sbm}
    An SBM is called symmetric if
    \begin{itemize}
        \item $p$ is \textbf{uniform}
        \item $\mathbf{W}$ takes the same value \textbf{on the diagonal} and the same value \textbf{off the diagonal} 
    \end{itemize}
    $(\mathbf{X},G)$ is drawn under $SSBM(n,k,A,B)$ if $p=\left\{ 1/k \right\}^k$ and $\mathbf{W}$ takes avlue $A$ on the diagonal and $B$ off the diagonal.
\end{definition}

\subsection{Recovery}
The goal of community detection is to recover the labels $\mathbf{X}$ by observing $G$, up to some level of accuracy. First, define \myhl[myred]{\textbf{agreement}} as 
\begin{definition}{Agreement of Communities}{community_agreement}
    The agreement between two community vectors $\mathbf{x,y}\in [k]^n$ is obtained by maximizing the common components between $\mathbf{x}$ and any relabelling of $\mathbf{y}$, that is 
    \begin{equation*}
        A(\mathbf{x,y}) = \max_{\pi\in S_k}\frac{1}{n}\sum^n_{i=1}\mathbf{1}\left[x_i = \pi(y_i)\right]
    \end{equation*}
    where $S_k$ is the group of permutations on $[k]$.
\end{definition}
The \textbf{relabelling} permutation is used to handle symmetric communities such as in SSBM, as it is impossible to recover the actual labels in this case.
But it's possible to recover the \textbf{partition}. There are 2 types of partition recovery we consider 

\paragraph*{Exact Recovery} 
First, consider the case of \myhl[myred]{\textbf{exact recovery}}:
\begin{definition}{Exact Recovery}{exact_recovery}
   Let $(\mathbf{X},G)\sim SBM(n,p,W)$, the exact recovery is solved if there exists an algorithm that takes $G$ as an input and outpus $\hat{\mathbf{X}} = \hat{\mathbf{X}}(G)$ such that $\mathbb{P}\left\{ A(\mathbf{X},\hat{\mathbf{X}}) =1 \right\} = 1-o_p(1)$ 
\end{definition}
In the SSBM case, algorithms that guarantee $$A(\mathbf{X},\hat{\mathbf{X}}) \rightarrow \frac{1}{k}$$ would be trivial.

\paragraph*{Weak Recovery} 
On the other hand, we the case of \myhl[myred]{\textbf{weak recovery}} defined as 
\begin{definition}{Weak Recovery}{weak_recovery}
    Weak recovery or detection is solved $SSBM(n,k,A,B)$ if for $(\mathbf{X},G)\sim SSBM(n,k,A,B)$, then $\exists \epsilon >0 $ and an algorithm that takes $G$ as an input and outputs $\hat{\mathbf{X}}$ such that 
    $$
    \mathbb{P}\left\{ A(\mathbf{X},\hat{\mathbf{X}})\geq \frac{1}{k} + \epsilon \right\} = 1-o(1)
    $$
\end{definition}

\subsection{Example: SSBM(n,2)}
Let's look at the example of $SSBM(n,2,\alpha\frac{\log n}{n},\beta \frac{\log n}{n})$, where 
\begin{itemize}
    \item $n$: number of vertices (assumed to be even for simplicity)
    \item for each $v\in [n]$, a binary label $X_v$ is attached s.t. $$ \left\vert \left\{ v\in [n]: X_v =1 \right\} \right\vert = n/2 $$
    \item for each pair of distinct nodes $u,v\in[n]$, an edge is placed with probability
    \begin{itemize}
        \item $\alpha \frac{\log n}{n}$ if $X_u=X_v$
        \item $\beta\frac{\log n}{n}$ if $X_u \neq X_v$
    \end{itemize}
    where edges are placed independently conditionally on the vertex labels
    \item WLOG, $\alpha > \beta$
\end{itemize}
then we have the following theorem 
\begin{theorem}{Exact Recovery in $SSBM(n,2,\alpha \log (n)/n,\beta \log(n)/n)$}{exact_recover_ssbm_n2}
    \begin{itemize}
        \item Exact recovery in $SSBM(n,2,\alpha \log (n)/n,\beta \log(n)/n)$ is solvable and efficiently so if $\left\vert \sqrt{\alpha} -\sqrt{\beta} \right\vert > \sqrt{2}$ nad unsolvable if $\left\vert \sqrt{\alpha} -\sqrt{\beta} \right\vert < \sqrt{2}$
        \item Exact recovery of the ground truth assignment of the partition $(A,B)$ is also achieveable, that is: if 
        $$ \frac{\alpha+\beta}{2} - \sqrt{\alpha\beta} >1 $$
        i.e. 
        $$ \alpha+\beta >2,\ \left(\alpha-\beta\right)^2 > 4\left(\alpha+\beta\right) - 4 $$
        the maximum likelihood estimator exactly recovers the communities (up to a global flip), with high probability.
    \end{itemize}
\end{theorem}
See \citet{abbe2017community} for the proof of this theorem. 

In summary, for a graph structure $G=(V,E)$ represented by adjacency matrix $\mathbf{X}_{n\times n}$, Stochastic Block Model (SBM)
\begin{itemize}
    \item assumes that there is a symmetric matrix $\mathbf{P} = \left\{ p_{ij} \right\} \in \mathbb{R}^{k\times k}$, for $k \ll n$ and a map $C:\left\{1,\cdots,n\right\} \rightarrow \left\{1,\cdots,k\right\}$, s.t. $\Pr\left(\mathbf{X}_{ij}=1\right) = \mathbf{P}_{C(i),C(i)}$
    \item Define $\boldsymbol{\Pi} = \left(\pi_1,\cdots,\pi_n\right)'\in \mathbb{R}^{n\times k}$ where $\boldsymbol{\Pi}_{ij}=1$ if $C(i)=j$, and $\boldsymbol{\Pi}_{ij}=0$ otherwise
    \item Let $\mathbf{H}= \mathbb{E}(\mathbf{X})$ be the probability matrix, then $\mathbf{H} = \boldsymbol{\Pi}\mathbf{P}\boldsymbol{\Pi}'$
    \item A variant of SBM is degree corrected SBM which incorporates the degree heterogeneity.
    \begin{itemize}
        \item each node is assigned a parameter $\theta_i >0$ such that $\Pr \left(\mathbf{X}_{ij}=1\right) = \theta_i\theta_j \mathbf{P}_{C(i),C(j)}$
        \item $\mathbf{H} = \boldsymbol{\Theta\Pi}\mathbf{P}\boldsymbol{\Pi'\Theta}$, where $\boldsymbol{\Theta} = \mathrm{diag} \left(\theta_1,\cdots,\theta_n\right)$
    \end{itemize}
\end{itemize}

\section{SIMPLE Model (Fan et al., 2022)}
In SBM, each $\pi_i\in\left\{e_1,\cdots,e_K \right\}$ with $e_k$ a one entry vector whose $k$-th component is one. But what if each node $i$ can belong to $K$ different communities? We generalize $\pi_i$ to be a compositional vector, and interpret it as community membership profile for node $i$, then 
$$
\Pr\left(\mathbf{X}_{ij}=1\right) = \theta_i\theta_j \sum^K_{k=1} \sum^K_{l=1} \pi_i(k)\pi_j(l)p_{kl}
$$
and $\mathbf{H} = \boldsymbol{\Theta\Pi}\mathbf{P}\boldsymbol{\Pi'\Theta}$. Now, consider a new statistical tests for testing whether any given pair of nodes share the same membership profiles, and providing the associated $p$-values.

\subsubsection{Problem Setting}
Consider an undirected graph $G=(V,E)$ with $n$ nodes, let $\mathbf{X}=\left\{x_{ij}\right\}\in \mathbb{R}^{n\times n}$

\newpage
\bibliographystyle{plainnat}
\bibliography{ref.bib}

\end{document}