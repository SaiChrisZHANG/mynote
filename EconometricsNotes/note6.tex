\documentclass[twoside]{article}
\input{settings.tex}

\begin{document}
\lecture{6}{DID and TWFE}{}{Sai Zhang}{This note is on the causal panel data, building upon \citet{arkhangelsky2023causal}.}{This note is compiled by Sai Zhang.}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

\section{Panel Data Configurations}

\subsection{Data Types}
\subsubsection{Panel Data}
For observations on $N$ units, indexed by $i=1,\cdots,N$, over $T$ periods, indexed by $t=1,\cdots,T$, the outcome of interest is denoted by $Y_{it}$, the treatment $W_{it}$.
These observations may themselves consist of averages over more basic units:
\begin{align*}
    \mathbf{Y} &= \begin{pmatrix}
        Y_{11} & \cdots & Y_{1T}\\
        \vdots & \ddots & \vdots \\
        Y_{N1} & \cdots & Y_{NT}
    \end{pmatrix} &
    \mathbf{W} = \begin{pmatrix}
        W_{11} & \cdots & W_{1T}\\
        \vdots & \ddots & \vdots \\
        W_{N1} & \cdots & W_{NT}
    \end{pmatrix}
\end{align*}
we may also observe exogenous variables $X_{it}$ or $X_i$. Typically, we focus on a balanced panel where for all units $i=1,\cdots,N$ we observe outcomes for all $t=1,\cdots,T$.

\subsubsection{Grouped Repeated Cross-Section Data}
In a GRCS data, we have observations on $N$ units, each observed only once in period $T_i$ for unit $i$. Different units may be observed at diffrent points in time, $T_i$ typically takes on only a few values, with many units sharing the same value for $T_i$. The outcome $Y_i$ and treatment $W_i$ are indexed by the unit index $i$.
The set of units is \textbf{partitioned} into 2 or more groups, with the group that unit $i$ belongs to denoted by $G_i\in \mathcal{G}=\left\{1,2,\cdots,G\right\}$.

Define the average outcomes for each group-time-period pair:
\begin{equation*}
    \bar{Y}_{gt} \equiv \frac{\sum^N_{i=1} \mathbf{1}_{G_i=g,T_i=t}Y_i}{\sum^N_{i=1} \mathbf{1}_{G_i=g,T_i=t}}
\end{equation*}
for treatment 
\begin{equation*}
    \bar{W}_{gt} \equiv \frac{\sum^N_{i=1} \mathbf{1}_{G_i=g,T_i=t}W_i}{\sum^N_{i=1} \mathbf{1}_{G_i=g,T_i=t}}
\end{equation*}
then treat the $G\times T$ group averages $\bar{Y}_{gt}$ and $\bar{W}_{gt}$ as the unit of observation, then the grouped data is just a panel.
The major issue in practice is that the number of groups is very small comparing to proper panel data.

\subsubsection{Row and Column Exchangeable Data}
The data are doubly indexed by $i=1,\cdots,N$ and $j=1,\cdots,J$, with outcomes $Y_{ij}$. They are different from panel data in that there is \textbf{no time ordering} for the second index. Many methods developed for panel data are also applicable here.

\subsection{Shapes of Data Frames}
Panel data can also be loosely classified by the shape:
\begin{itemize}
    \item \myhl[myblue]{\textbf{Thin Frames} $(N\gg T)$}, where the number of cross-section units is large relative to the number of time periods:
    \begin{itemize}
        \item unit-specific parameters (individual FEs) \textbf{can not be estimated consistently} due to the short time series
        \item REs might be more suitable since they place a stocahstic structure on the individual components
    \end{itemize}
    \item \myhl[myblue]{\textbf{Fat Frames} $(N\ll T)$}, where the number of cross-section units is large relative to the number of time periods.
    \item \myhl[myblue]{\textbf{Square} $N\simeq T$}, where the number of units and time periods is comparable.
\end{itemize}

\subsection{Assignment Mechanisms}
\subsubsection{The General Case}
In the most general case, the treatment may vary both across units and over time, with units \textbf{switching} in and out of the treatment group:
\begin{equation*}
    \mathbf{W}^{\text{general}} = \begin{pmatrix}
        1&1&0&0&\cdots &1\\
        0&0&1&0&\cdots &0\\
        1&0&1&1&\cdots &0\\
        \vdots &\vdots & \vdots & \vdots & \ddots & \vdots \\
        1&0&1&0&\cdots &0
    \end{pmatrix}
\end{equation*}
This is more relevant for the RCED configurations, and for panel data of products and promotions as treatments.
The assumption on the absence/presence of \textbf{dynamic treatment} effects is very important.

\subsubsection{Single Treated Period}
One special case arises when a substantial number of units is treated, but these units are only treated \textbf{in the last period}
\begin{equation*}
    \mathbf{W}^{\text{last}} = \begin{pmatrix}
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &1\\
        \vdots &\vdots & \vdots & \vdots & \ddots & \vdots \\
        0&0&0&0&\cdots &1
    \end{pmatrix}
\end{equation*}
If $T$ is relatively small, this case is often analyzed as a cross-section problem, the lagged outcomes are used as exogenous covariates or pre-treatment variables to be adjusted.
Here, dynamic effects are not testable, nor do they matter since the shortness of the panel.
\begin{equation*}
    \mathbf{W}^{\text{last}} = \begin{pmatrix}
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &0\\
        \vdots &\vdots & \vdots & \vdots & \ddots & \vdots \\
        0&0&1&1&\cdots &0
    \end{pmatrix}
\end{equation*}
this setting is prominent in the original applications of the synthetic control literature, here $T$ is usually small.

\subsubsection{Single Treated Unit and Single Treated Period}
An extreme case is where only a single unit is treated, and it is only treated in a single period (typically the last). 
\begin{equation*}
    \mathbf{W}^{\text{block}} = \begin{pmatrix}
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &0\\
        \vdots &\vdots & \vdots & \vdots & \ddots & \vdots \\
        0&0&0&0&\cdots &1
    \end{pmatrix}
\end{equation*}
Normally, we focus on the effect for the single treated/time-period pair and construct prediction intervals.

\subsubsection{Block Assignment}
The case of block assignment is where a subset of units is treated every period after a common starting date:
\begin{equation*}
    \mathbf{W}^{\text{block}} = \begin{pmatrix}
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &0\\
        0&0&1&1&\cdots &1\\
        \vdots &\vdots & \vdots & \vdots & \ddots & \vdots \\
        0&0&1&1&\cdots &1
    \end{pmatrix}
\end{equation*}
There is typically a sufficient number of treated unit/time-period pairs to allow for reasonable approximations. The presence of dynamic effects change the interpretation of the average effect of the treated: the average effect for the treated now is an average over short \textbf{and} medium term effects during different periods.

\subsubsection*{Staggered Adoption (a.k.a. absorbing treatment setting)}
The staggered adoption is the case where units adopt the treatment at various period, and remain in the treatment group once they adopt the treatment:
\begin{equation*}
    \mathbf{W}^{\text{block}} = \begin{pmatrix}
        0&0&0&0&\cdots &0\\
        0&0&0&0&\cdots &1\\
        0&0&0&1&\cdots &1\\
        \vdots &\vdots & \vdots & \vdots & \ddots & \vdots \\
        0&0&1&1&\cdots &1
    \end{pmatrix}
\end{equation*}
Here, with some assumptions, we can separate dynamic effects from heterogeneity across calendar time.

\subsubsection{Event Study Designs}
In the event-study design, units are exposed to the treatment in at most one period:
\begin{equation*}
    \mathbf{W}^{\text{block}} = \begin{pmatrix}
        0&0&0&0&\cdots &0\\
        1&0&0&0&\cdots &0\\
        0&1&0&0&\cdots &0\\
        \vdots &\vdots & \vdots & \vdots & \ddots & \vdots \\
        0&0&0&1&\cdots &0
    \end{pmatrix}
\end{equation*}
There are often dynamic effects of the treatment past hte time of initial treatment, however, the effects might be changing over time.

\subsubsection{Clustered Assignment}
In many applications, units are grouped together in clusters. Units within the same clusters are always assigned to the treatment:
\begin{equation*}
    \mathbf{W}^{\text{cluster}} = \begin{pmatrix}
        &&&&&&&\text{cluster}\\
        0&0&0&0&\cdots &0&0&1\\
        0&0&0&0&\cdots &0&0&1\\
        0&0&0&0&\cdots &0&0&2\\
        0&0&0&0&\cdots &0&0&2\\
        0&0&0&0&\cdots &1&1&3\\
        \vdots&\vdots&\vdots&\vdots&\ddots &\vdots&\vdots&\vdots\\
        0&0&0&1&\cdots &1&1&C\\
        0&0&0&1&\cdots &1&1&C
    \end{pmatrix}
\end{equation*}
Clustering creates complications for inference.

\subsection{Outcomes, Assumptions and Estimands}
For a treatment assignment matrix $\mathbf{W}$, denote:
\begin{itemize}
    \item the full $T-$component column vector of treatment assignments as $$ \underline{\mathbf{w}} \equiv \left(w_1,\cdots,w_T\right)' $$
    \item the $t$-component column vector of treatment assignments \myhl[myblue]{\textbf{up to} time $t$} as $$ \underline{\mathbf{w}}^{t} \equiv \left(w_1,\cdots,w_t\right)' $$ hence $\underline{\mathbf{w}}^T=\underline{\mathbf{w}}$
    \item the row vector of treatment values for unit $i$ as $\underline{\mathbf{W}}_i$
\end{itemize}
Then in general, we can index the potential outcomes for unit $i$ in period $t$ by the full $T-$component vector of assignments $\underline{\mathbf{w}}$
$$Y_{it}\left(\underline{\mathbf{w}}\right)$$
A key underlying assumption is the \myhl[myblue]{\textbf{Stable Unit Treatment Value Assumption (SUTVA)}}, which requires that there is no interference or spillovers between units\footnote{SUTVA can hold on a cluster/group level, where the spillover effects are within clusters/groups.}.

In this setup, there are $2^T$ potential outcomes for each unit and each time period, as a function of multi-valued treatment $\underline{\mathbf{w}}$. Then, define for each $t$-unit treatment effects for each pair of assignment vectors $\underline{\mathbf{w}}$ and $\underline{\mathbf{w}}'$: $$ \tau^{\underline{\mathbf{w}},\underline{\mathbf{w}}'}_{it}\equiv Y_{it}\left(\underline{\mathbf{w}}'\right) - Y_{it}\left(\underline{\mathbf{w}}\right) $$
and the corresponding population average effect $$ \tau_t^{\underline{\mathbf{w}},\underline{\mathbf{w}}'}\equiv \mathbb{E}\left[Y_{it}\left(\underline{\mathbf{w}}'\right)-Y_{it}\left(\underline{\mathbf{w}}\right) \right] $$
where the expectation is implicitly assumed to be taken over a \textbf{large} population.

Under completely random assignment, all $\tau_t^{\underline{\mathbf{w}},\underline{\mathbf{w}}'}$ are identified, and are \textbf{just-identified}, given sufficient variation in the treatment paths. Dynamic treatment effects can also be identified\footnote{For example, consider that in the 2-period case $$ \tau_2^{(1,1),(0,1)} $$ is the average effect in the second period of being exposed to $(1,1)$, \textit{treated in both period}, rather than $(0,1)$, \textit{treated only in the second period}.}.
However, we have \myhl[myblue]{$2^{T-1}\times \left(2^T-1\right)$} distinct average effects of the form $\tau_t^{\underline{\mathbf{w}},\underline{\mathbf{w}}'}$,
in practice, we often need to focus on summary measures of these causal effects, which requires some addition assumptions:

\begin{assumption}{No Anticipation}{no_anticipation}
    The potential outcomes satisfy $$ Y_{it}\left(\underline{\mathbf{w}}\right) = Y_{it}\left(\underline{\mathbf{w}}'\right)$$ for all $i$, and for all combinations of $t$, $\underline{\mathbf{w}}$ and $\underline{\mathbf{w}}'$ such that $\underline{\mathbf{w}}t=\underline{\mathbf{w}}'^{t}$. 
\end{assumption}
This is a testable assumption with experimental data and sufficient variation in treatment paths, by comparing units that have the same treatment path up to and including $t$ and diverge after $t$.
\begin{itemize}
    \item \underline{Units \textbf{are not} active decision-makers}: the assumption can be guaranteed by design (random treatment assignment each period, or staggered adoption with randomly assigned adoption date)
    \item \underline{\textbf{Limited} antici}p\underline{ation}: assuming the treatment can be anticipated for a \textbf{fixed number} of periods, which shifts $\underline{\mathbf{w}}$ by that number of periods.
    \item \underline{Units \textbf{are} active decision-makers}: potential outcomes are functions of $\underline{\mathbf{w}}$ and the distribution of $\underline{\mathbf{w}}$ (experimental design itself):
    \begin{itemize}
        \item one can define potential outcomes for a given randomized experimental design: the beliefs about the future treatment paths are incorporated in the definition of the potential outcomes, the actual values are by construction unknown. This does change the interpretation of the casual effects\footnote{Think about the differences between a surprise deviation from a given policy rule versus the effect of a permanent chagne int he policy rule itself.}.
        \item In obserational studies, one cannot directly control the information about the future treatment paths. In this case, different units need to be gauranteed to face the \textbf{same information environment} for Assumption \ref{assump:no_anticipation} to hold.
    \end{itemize}
\end{itemize}
Under Assumption \ref{assump:no_anticipation}, the total number of potential treatment effects is reduced from $2^{T-1}\times \left(2^T-1\right)$ to $\left(\sum^T_{t=1}2^{t-1}\right)\left(\sum^T_{t=1}2^t-1\right)$. The unit-period specific treatment effects are now of the type 
\begin{equation*}
    \tau^{\underline{\mathbf{w}}^t,\underline{\mathbf{w}}^{t'}}_{it} \equiv Y_{it}\left(\underline{\mathbf{w}}^{t'}\right) - Y_{it}\left(\underline{\mathbf{w}}^t\right)
\end{equation*}
with the potential outcomes for period $t$ indexed by treatments up to period $t$ only. Here, one can still distinguish
\begin{itemize}
    \item static treatment effects: $\tau_{it}^{\left(\underline{\mathbf{w}}^{t-1},0\right),\left(\underline{\mathbf{w}}^{t-1},1\right)}$, which measures the response of current outcome to the current treatment, holding the past ones fixed.
    \item dynamic treatment effects: $\tau_{it}^{\left(\underline{\mathbf{w}}^{t-1},w^t\right),\left(\underline{\mathbf{w}}^{t-1},w^t\right)}$, which does the opposite.
\end{itemize}

\begin{assumption}{No Dynamic/Carry-Over Effects}{no_dynamic}
    The potential outcomes satisfy $$ Y_{it}\left(\underline{\mathbf{w}}\right) = Y_{it}\left(\underline{\mathbf{w}}'\right) $$
    for all $i$ and for all combinations of $t$, $\underline{\mathbf{w}}$ and $\underline{\mathbf{w}}'$ such that $w_{it}=w'_{it}$.
\end{assumption}
This assumption is \textbf{not} guaranteed by randomization. It restricts the treatment effects and the potential outcomes for the \textbf{post}-treatment periods.
It has testable restrictions given the random assignment of the treatment and sufficient variation in the treatment paths. It does \textbf{not} restrict the time path of the potential outcomes in the absence of any treatment $Y_{it}\left(\mathbf{0}\right)$.

This assumption greatly reduce the total number of treatment effects for each unit to $T$:
$$ \tau_{it}\equiv Y_{it}(1) - Y_{it}(0)$$
where $\tau_{it}$ has no superscripts because there are only 2 possible arguments of the potential outcomes $w\in \left\{0,1\right\}$.

\begin{assumption}{Staggered Adoption}{stag_adopt}
    In staggered adoption, $$W_{it}\leq W_{it-1},\ \forall t=2,\cdots,T$$
    define the adoption date $A_i$ as the date of the first treatment, $A_i\equiv T+1-\sum^T_{t=1}W_{it}$ for treated units, and $A_i\equiv \infty$ for never-treated units.
\end{assumption}
Under Assumption \ref{assump:stag_adopt}, the potential outcomes can be written in terms of the adoption date as $Y_{it}(a)$, for $a=1,\cdots,T,\infty$, and the realized outcome as $Y_{it}=Y_{it}\left(A_i\right)$. There are 2 broad classes of settings that are viewed as staggered adoption designs:
\begin{itemize}
    \item interventions adopted and remain in place 
    \item one-time interventions with a long-term, or even permanent, impact (where the post-intervention period effects are dynamic effects)
\end{itemize}
Under Assumption \ref{assump:stag_adopt}, but \textbf{not} Assumption \ref{assump:no_anticipation} and \ref{assump:no_dynamic}, we can write 
$$ \tau_{it}^{a,a'}\equiv Y_{it}\left(a'\right)-Y_{it}(a) $$
with the corresponding population average
$$ \tau_t^{a,a'}\equiv \mathbb{E}\left[ \equiv Y_{it}\left(a'\right)-Y_{it}(a) \right] $$
we can also denote the average for subpopulations conditional on the adoption dates as 
$$ \tau_{t\mid a''}^{a,a'}\equiv \mathbb{E}\left[\equiv Y_{it}\left(a'\right)-Y_{it}(a)\mid A_i=a''\right] $$
which explicitly depends on the details of the assignment process. This estimand is conceptually similar to the average effect on the treated in cross-sectional settings, but with selection operating over both unit and period dimensions.

\subsection{Conventional TWFE and DiD}
\subsubsection{TWFE Characterization}
First, consider a panel setting with no anticipation, no dynamics, and constant treatment effects:
\begin{assumption}{The TWFE Model}{twfe_model}
    The control outcome $Y_{it}(0)$ satisfies $$ Y_{it}(0) = \alpha_i + \beta_t + \epsilon_{it} $$
    The unobserved component $\epsilon_{it}$ is (mean-)independent of the treatment assignment $W_{it}$
\end{assumption}
And 
\begin{assumption}{Constant Static Treatment Effects}{const_stat_treat}
    The potential outcomes satisfy $$ Y_{it}(1) = Y_{it}(0) + \tau \ \ \forall (i,t) $$
\end{assumption}
Under Assumption \ref{assump:twfe_model} and \ref{assump:const_stat_treat}, for the realized $Y_{it}\equiv W_{it}Y_{it}(1) + \left(1-W_{it}\right)Y_{it}(0)$ we have a model 
$$ Y_{it} = \alpha_i + \beta_t +\tau W_{it}+\epsilon_{it} $$
then we can estimate the parameters of this model by least squares
\begin{equation*}
    \left(\hat{\tau}^{TWFE},\hat{\alpha},\hat{\beta}\right) = \arg\min_{\tau,\alpha,\beta} \sum^N_{i=1}\sum^T_{t=1} \left(Y_{it}-\alpha_i-\beta_t -\tau W_{it}\right)^2
\end{equation*}
one restriction on the $\alpha_i$ or $\beta_t$ needs to be imposed to avoid perfect collinearity, but this normalization does not affect the estimation of $\tau$.

Under a block assignment structure, we have $W_{it}=1$ only for a subset of the units\footnote{The \textit{treatment group} with $i\in \mathcal{J}$, where the cardinality for the set $\mathcal{J}$ is $N^{\mathrm{tr}}$ and $N^{\mathrm{co}}\equiv N-N^{\mathrm{tr}}$.}, and those units are treated only during periods $t$ with $t>T_0$.
Define the averages in the four groups as 
\begin{align*}
    \bar{Y}^{\mathrm{tr,post}} &\equiv \frac{\sum_{i\in\mathcal{J}}\sum_{t>T_0}Y_{it}}{N^{\mathrm{tr}}\left(T-T_0\right)} & \bar{Y}^{\mathrm{tr,pre}} &\equiv \frac{\sum_{i\in\mathcal{J}}\sum_{t\leq T_0}Y_{it}}{N^{\mathrm{tr}}T_0} \\
    \bar{Y}^{\mathrm{co,post}} &\equiv \frac{\sum_{i\not\in\mathcal{J}}\sum_{t>T_0}Y_{it}}{N^{\mathrm{co}}\left(T-T_0\right)} & \bar{Y}^{\mathrm{co,pre}} &\equiv \frac{\sum_{i\not\in\mathcal{J}}\sum_{t\leq T_0}Y_{it}}{N^{\mathrm{co}}T_0}
\end{align*}
and then write the estimator for the treatment effect as 
\begin{equation*}
    \hat{\tau}^{TWFE} = \left(\bar{Y}^{\mathrm{tr,post}}-\bar{Y}^{\mathrm{tr,pre}}\right) - \left(\bar{Y}^{\mathrm{co,post}}-\bar{Y}^{\mathrm{co,pre}}\right)
\end{equation*}

\subsubsection{DiD Estimator in the Grouped Repeated Cross-Section Setting}
In GRCS setting, we observe each physical unit only once. With blocked assignment, the notation only has a single index for the unit $i=1,\cdots,N$.
Let $G_i\in\mathcal{G}=\left\{1,\cdots,G\right\}$ denote the cluster or group unit $i$ belongs to, and $T_i\in \left\{1,\cdots,N\right\}$ the time period unit $i$ is observed in.

The set of clusters $\mathcal{G}$ is partitioned into two groups: control group $\mathcal{G}_C$ and treatment group $\mathcal{G}_T$, with cardinality $G_C$ and $G_T$. Only units with $G_i\in \mathcal{G}_T$, indicated by $D_i=\mathbf{1}_{G_i\in\mathcal{G}_T}$, are exposed to the treatment if they are observed after the treatment date $T_0$: $W_i=\mathbf{1}_{G_i\in\mathcal{G}_T,T_i>T_0}$

Assuming that the treatment within group and time period pairs is constant, the cluster/time-period average treatment $\bar{W}_{gt}$ is binary if the original treatment is. Then the DiD estimator is 
\begin{align*}
    \hat{\tau}^{DiD} =& \frac{1}{G_T\left(T-T_0\right)} \sum_{g\in\mathcal{G}_T,t>T_0} \bar{Y}_{gt} - \frac{1}{G_C\left(T-T_0\right)} \sum_{g\in\mathcal{G}_C,t>T_0}\bar{Y}_{gt}\\
    &- \frac{1}{G_TT_0}\sum_{g\in\mathcal{G}_T,t\leq T_0} \bar{Y}_{gt} + \frac{1}{G_CT_0}\sum_{g\in\mathcal{G}_C,t\leq T_0}\bar{Y}_{gt}
\end{align*}
and at the group level, we have a proper panel setup:
\begin{align*}
    \bar{Y}_{gt}(0) &= \alpha_g+\beta_t+\epsilon_{gt} & \bar{Y}_{gt}(1) &\bar{Y}_{gt}(0)+\tau
\end{align*}
and the potential outcomes $\bar{Y}_{gt}(0)$ and $\bar{Y}_{gt}(1)$ should be interpreted as the average of the potential outcomes if all units in a group/time-period pair are exposed to the control treatment.

\subsubsection{Inference}
There are two ways to conduct inference about $\hat{\tau}^{\mathrm{DiD}}$ and $\hat{\tau}^{\mathrm{TWFE}}$:
\begin{itemize}
    \item the assignment process is known: \myhl[myblue]{\textbf{design-based}} or \myhl[myblue]{\textbf{randomization-based}} inference
    \item otherwise: \myhl[myblue]{\textbf{sampling-based}} inference
\end{itemize}

\paragraph*{Design-Based Inference}


\paragraph*{Sampling-Based Inference}
\begin{itemize}
    \item \myhl[myblue]{\textbf{proper panel setting}}: it is often assumed that all units are randomly sampled from a large population and thus \textbf{exchangeable}. Inference about $\hat{\tau}^{\mathrm{TWFE}}$ reduces to joint inference about four means with i.i.d. observations.
    \item \myhl[myblue]{\textbf{GRCS setting}}: one can allow for non-vanishing errors at the group level, but it cannot be done in the two-group case.
\end{itemize}

\subparagraph*{Standard errors}
Regardless of the level of aggregation, inference for TWFE and DiD estimators typically takes into account the correlation in outcomes over time within units in applications with more than two periods. So it is \textbf{NOT} appropriate to use the robust Eicker-Huber-White standard errors. 
Instead, one should use clustered standard errors based on clustering observations by units. It can also be approximated by bootstrapping all observations for each unit.

\subsubsection{The Parallel Trend Assumption}

The \textbf{parallel trend assumption} is the fundamental justification for the DiD estimator. It states that the units who are treated would have followed a path that is parallel to the path followed by the control units on average, in the absence of the treatment.

\paragraph*{Proper panel settings} the assumption is that the expected difference in control outcomes in any period for units who later are exposed to the treatment and units who are always in the control group is \textbf{contstant}:
\begin{assumption}{Parallel Trend Assumption: Proper Panel}{parallel_trend_panel}
    For all $t,t'$,
    \begin{equation*}
        \mathbb{E}\left[Y_{it}\left(0\right)\mid D_i=1\right] - \mathbb{E}\left[Y_{it}\left(0\right)\mid D_i=0\right] = \mathbb{E}\left[Y_{it'}\left(0\right)\mid D_i=1\right] - \mathbb{E}\left[Y_{it'}\left(0\right)\mid D_i=0\right]
    \end{equation*}
    equivalently, we can formulate it in terms of changes over time\footnote{the expected change in control outcomes is the same for those who will eventually be exposed to the treatment and those who will not}:
    \begin{equation*}
        \mathbb{E}\left[Y_{it}(0)-Y_{it'}(0)\mid D_i=1\right] = \mathbb{E}\left[Y_{it}(0)-Y_{it'}(0)\mid D_i=0\right]
    \end{equation*}
    alternatively, postulate a TWFE model for the control outcomes, additionally assuming that the treatment assignment $D_i$ is independent of the vector of residuals $\epsilon_{it},t=1,\cdots,T$, conditional on FEs: 
    \begin{equation*}
        D_i \perp \left(\epsilon_{i1},\cdots,\epsilon_{iT}\right) \mid \alpha_i 
    \end{equation*}
\end{assumption}
From the point of view of the modern casual inference literature, the parallel trend assumption is non-standard in the sense that it combbines restrictions on the potential outcomes with restrictions on the assignment mechanism.

\paragraph*{GRCS settings} Suppose in the population, all groups are (infinitely) large in each period, and we have random samples from these populations for each period. Then the expectations are well defined as population averages.
The parallel trends assumption can the nbe formulated as requiring that the difference in expected control outcomes between two groups remains constant over time: 
\begin{assumption}{Parallel Trend Assumption: Grouped Repeated Cross-Section}{parallel_trend_grcs}
    For all pairs of groups $g,g'$ and for all pairs of time periods $t,t'$, the average difference between the groups remains the same over time, irrespective of their treatment status: 
    \begin{equation*}
        \mathbb{E}\left[Y_{gt}(0)\mid D_i=1\right] - \mathbb{E}\left[Y_{g't}(0)\mid D_i=0\right] = \mathbb{E}\left[Y_{gt'}(0)\mid D_i=1\right] - \mathbb{E}\left[Y_{g't'}(0)\mid D_i=0\right]
    \end{equation*}
    an alternative formulation is that expected change between periods $t'$ and $t$ is the same for all groups:
    \begin{equation*}
        \mathbb{E}\left[Y_{gt}(0)\mid D_i=1\right] - \mathbb{E}\left[Y_{gt'}(0)\mid D_i=1\right] = \mathbb{E}\left[Y_{g't}(0)\mid D_i=0\right] - \mathbb{E}\left[Y_{g't'}(0)\mid D_i=0\right]
    \end{equation*}
\end{assumption}
If $Y_{gt}(0)$ for all $g$ and $t$ are observed, the presence of the two groups and two time periods would be sufficient for the assumption to have testable implications. However, in the 2-group/2-period case, at least one of the four cells is exposed to the treatment, there are no testable restrictions implied by this assumption\footnote{If there are more than 2 periods, or more than 2 groups, there are testable restrictions by the parallel trend assumption.}.

\subsubsection{Pre-treatment Variables}

Time-invariant characteristics of the units in addition to the time path of the outcome are observed, these variables are colinear with the individual fixed effects $\alpha_i$ hence cannot be incorporated simply by adding them to the TWFE specification.
A reason one might want to include these pre-treatment variables is that the parallel trend and constant treatment effect assumptions hold only within subpopulations defined by them.

\paragraph*{Semi-parametric DiD}
\citet{abadie2005semiparametric} proposed a solution based on \textbf{re-weighting} the differences in outcomes by the propensity score for balance. TO estimate the average treatment effect on the treated (ATT):
\begin{equation*}
    ATT\equiv \mathbb{E}\left(\mathbf{y}_{1t}-\mathbf{y}_{0t}\mid \mathbf{d}=1\right)
\end{equation*}
where the 2 potential outcomes $\mathbf{y}_{1t}$ is the value of $\mathbf{y}$ if the participant received the treatment by $t$, $\mathbf{y}_{0t}$ is the value of $\mathbf{y}$ if the participant had not received the treatment by time $t$. $\mathbf{d}$ is an indicator of treatment.

ATT cannot be directly estimated since $\mathbf{y}_{0t}$, the counterfactual, is never observed. For a set of pretreatment characteristics $\mathbf{x}_{b}$, define the probability to be in the treatment group conditional on $\mathbf{x}_b$ as $$ \pi\left(\mathbf{x}_b\right)\equiv \mathbb{P}\left(\mathbf{d}=1\mid \mathbf{x}_b\right) $$
define the change of $\mathbf{y}$ from baseline $b$ to $t$ as $$\Delta \mathbf{y}_t \equiv \mathbf{y}_t - \mathbf{y}_b $$
then
\begin{equation}\label{eq:abadie_att_estimate}
    \mathbb{E}\left\{ \frac{\Delta \mathbf{y}_t}{\mathbb{P}\left(\mathbf{d}=1\right)} \times \frac{\mathbf{d}-\pi\left(\mathbf{x}_b\right)}{1-\pi\left(\mathbf{x}_b\right)} \right\}
\end{equation}
gives an unbiased estimate of the ATT if 
\begin{align*}
    \mathbb{E}\left(\mathbf{y}_{0t}-\mathbf{y}_{0b}\mid \mathbf{d}=1,\mathbf{x}_b\right) &= \mathbb{E}\left(\mathbf{y}_{0t}-\mathbf{y}_{0b}\mid \mathbf{d}=0,\mathbf{x}_b\right)\\
    \mathbb{P}\left(\mathbf{d}=1\right) &>0\\
    \pi\left(\mathbf{x}_b\right) &<1
\end{align*}
This estimator is a weighted average of the difference of trend, $\Delta \mathbf{y}_t$, across treatment groups: it reweights the trend of the untreated based on the propensity score $\pi\left(\mathbf{x}_b\right)$\footnote{$\frac{\pi\left(\mathbf{x}_b\right)}{1-\pi\left(\mathbf{x}_b\right)}$ is an increasing function of $\pi\left(\mathbf{x}_b\right)$, hence untreated participants with a higher propensity score are given a higher weight.}.

\citet{abadie2005semiparametric} suggests to approximate the propensity score $\pi\left(\mathbf{x}_b\right)$ semiparametrically using a polynomial series of the predictors and plug the predicted values into the sample analogue of the ATT estimates \ref{eq:abadie_att_estimate}.
There are two main ways to do the approximation:
\begin{itemize}
    \item \textbf{linear probability model (LPM)}: higher order improves the approximation, but less precise
    \item \textbf{series logit estimator (SLE)}: using a logit specification to constrain the estimated propensity score to vary between 0 and 1
\end{itemize}

consider $\hat{\pi}\left(\mathbf{x}_b\right)$, the approximated propensity score, and $k$, the order of the polynomial function for approximation. Then the \textbf{LPM} approximation is 
\begin{align*}
    \hat{\pi}\left(\mathbf{x}_b\right) = \hat{\gamma}_0 + \hat{\gamma}_1 \times \mathbf{x}_1 + \sum^k_{i=1}\hat{\gamma}_{2i}\times \mathbf{x}^i_2
\end{align*}
where $\mathbf{x}_1$ is a binary variable, $\mathbf{x}_2^i = \prod^i_{j=1}\mathbf{x}_2$, with $\mathbf{x}_2$ being a continuous variable. Then the coefficients $\hat{\gamma}_0,\hat{\gamma}_1,\hat{\gamma}_{21},\cdots,\hat{\gamma}_{2i},\cdots,\hat{\gamma}_{2k}$ are estimated using OLS estimators.

The \textbf{SLE} approximation is 
\begin{equation*}
    \hat{\pi}\left(\mathbf{x}_b\right) = \Lambda\left(\hat{\gamma}_0 + \hat{\gamma}_1\times \mathbf{x}_1 + \sum^K_{k=1}\hat{\gamma}_{2k}\times \mathbf{x}^k_2\right)
\end{equation*}
where $\Lambda(x) = \frac{\exp(x)}{1+\exp(x)}$ is the logistic function. Higher order binary variables are not considered here since $\mathbf{x}_1^k=\mathbf{x}_1$ for any value $k>1$.

\paragraph*{Doubly robust DiD} \citet{sant2020doubly} adjust for time-invariant covariates in a doubly robust way, by combining inverse-propensity score weighting with outcome modeling. 

\paragraph*{Timing varying covariates}
With finite $T$, strictly exogenous time-varying covariates $X_{it}$ can be converted to time invariant $X_i\equiv \left(X_{i1},\cdots,X_{iT}\right)$, in practice, applied researchers only rely on linear specifications with contemporaneous covariates instead.

\citet{sant2020doubly} also assume that covariates and treatment status are stationary as \citet{abadie2005semiparametric}. Let $T_i$ be a dummy variable that takes value one if the observation $i$ is only observed in the post-treatment period, and 0 if only observed in the pre-treatment period. Define $Y_i = T_iY_{i1}+\left(1-T_i\right)Y_{i0}$. Let $n_1$ and $n_0$ be the sample size of the post- and pre-treatment periods such that $n=n_1+n_0$, and let $\lambda = \mathbb{P}\left(T=1\right)\in \left(0,1\right)$:
\begin{assumption}{Main assumptions of \citet{sant2020doubly}}{santanna_zhao}
    Assume that
    \begin{itemize}
        \item[1] the data $\left\{Y_{i0},Y_{i1},D_i,X_i\right\}^n_{i=1}$ are \textbf{i.i.d.}, or the pooled repeated cross-section data $\left\{Y_i,D_i,X_i,T_i\right\}^n_{i=1}$ consisting of i.i.d. draws from the mixture distribution
        \begin{align*}
            \mathbb{P}\left(Y\leq y, D=d, X\leq x, T=t\right) =& t\cdot \lambda \cdot \mathbb{P}\left(Y_1\leq y, D=d, X\leq x \mid T=1\right)\\
            &+ \left(1-t\right)\cdot \left(1-\lambda\right) \mathbb{P}\left(Y_0\leq y, D=d, X\leq x \mid T=0\right)
        \end{align*}
        where $\left(y,d,x,t\right)\in \mathbb{R}\times \left\{0,1\right\}\times \mathbb{R}^k\times \left\{0,1\right\}$, with the joint distribution of $\left(D,X\right)$ invariant to $T$.
        \item[2] \textbf{Conditional Parallel Trend Assumption (PTA)}\footnote{It allows for covariate-specific time trends but not unit specific trends.}: $$ \mathbb{E}\left[Y_1(0)-Y_0(0)\mid D=1,X\right] \overset{a.s.}{=} \mathbb{E}\left[Y_1(0)-Y_0(0)\mid D=1,X\right] $$
        \item[3] $\exists \epsilon>0$, $\mathbb{P}\left(D=1\right)>\epsilon$ and $\mathbb{P}\left(D=1\mid X\right)\leq 1-\epsilon$ a.s.\footnote{This overlapping condition states that at least a small fraction of the population is treated and that for every value of $X$, at least a small probability that the unit is not treated.}
    \end{itemize}
\end{assumption}
Under Assumption \ref{assump:santanna_zhao}, there are 2 main flexible estimation procedures to estimate the ATT:
\begin{itemize}
    \item[1] outcome regression (\textbf{OR}) approach
    \begin{equation*}
        \hat{\tau}^{\mathrm{reg}} = \bar{Y}_{1,1}-\left[ \bar{Y}_{1,0} + n^{-1}_{\mathrm{treat}} \sum_{i\mid D_i=1}\left(\hat{\mu}_{0,1}\left(X_i\right) - \hat{\mu}_{0,0}\left(X_i\right) \right) \right]
    \end{equation*}
    where $\bar{Y}_{d,t}= \sum_{i\mid D_i=d,T_i=t}Y_{it}/n_{d,t}$ is the sample average outcome among units in treatment group $d$ and time $t$, $\hat{\mu}_{d,t}(x)$ is an estimator of the unknown $m_{d,t}(x)\equiv \mathbb{E}\left[Y_t\mid D=d,X=x\right]$
    \item[2] inverse propensity weighting (\textbf{IPW}) approach, as in \citet{abadie2005semiparametric}.
\end{itemize}

\citet{sant2020doubly} proposed to combine both the \textbf{OR} and \textbf{IPW} approaches to form the doubly robust (\textbf{DR}) moments/estimands for the ATT.

\subparagraph*{Notation} Let $\pi(X)$ be an arbitrary model for the true, unknown propensity score.
\begin{itemize}
    \item with proper panel data, let $\Delta Y= Y_1-Y_0$ and define $\mu^p_{d,\Delta}(X)\equiv \mu^p_{d,1}(X)-\mu^p_{d,0}(X)$ being a model for the true, unknown outcome regression $m^p_{d,t}(x)\equiv \mathbb{E}\left[Y_t\mid D=d,X=x\right]$, $d,t=0,1$. 
    \item with repeated cross-section data, let $\mu_{d,t}^{rc}(x)$ be an arbitrary model for the true, unknown regression $m^{rc}_{d,t}(x)\equiv \mathbb{E}\left[Y\mid D=d,T=t,X=x\right], d,t=0,1$, $\mu_{d,Y}^{rc}(T,X)\equiv T\cdot \mu^{rc}_{d,1}(X)+(1-T)\cdot \mu^{rc}_{d,0}(X)$, and $\mu^{rc}_{d,\Delta}(X)\equiv \mu^{rc}_{d,1}(X)-\mu^{rc}_{d,0}(X)$.
\end{itemize}

\paragraph*{Estimands} consider
\begin{itemize}
    \item for proper panel data: 
    \begin{equation*}
        \tau^{dr,p} = \mathbb{E}\left[ \left(w^p_1(D)-w^p_0\left(D,X;\pi\right)\right) \left(\Delta Y-\mu^p_{0,\Delta}(X)\right) \right]
    \end{equation*}
    where, for a generic $g$,
    \begin{align*}
        w^p_1(D) &= \frac{D}{\mathbb{E}\left[D\right]} & w^p_0\left(D,X;g\right)&= \frac{g(X)(1-D)}{1-g(X)}\cdot \left(\mathbb{E}\left[\frac{g(X)(1-D)}{1-g(X)}\right]\right)^{-1}
    \end{align*}
    \item for repeated cross-section data, consider 2 different estimands
    \begin{align*}
        \tau_1^{dr,rc} =& \mathbb{E}\left[\left(w^{rc}_1(D,T)-w_0^{rc}\left(D,T,X;\pi\right)\right) \cdot \left(Y-\mu^{rc}_{0,Y}(T,X)\right)\right] \\
        \tau^{dr,rc}_2 =& \tau^{dr,rc}_1 + \left(\mathbb{E}\left[\mu^{rc}_{1,1}(X)-\mu^{rc}_{0,1}(X)\mid D=1\right] -\mathbb{E}\left[\mu^{rc}_{1,1}(X)-\mu^{rc}_{0,1}(X)\mid D=1,T=1\right] \right)\\
        &- \left( \mathbb{E}\left[\mu^{rc}_{1,0}(X)-\mu^{rc}_{0,0}(X)\mid D=1\right] - \mathbb{E}\left[\mu^{rc}_{1,0}(X)-\mu^{rc}_{0,0}(X)\mid D=1,T=0\right] \right)
    \end{align*}
    where for a generic $g$,
    \begin{align*}
        w^{rc}_1(D,T)&=w^{rc}_{1,1}(D,T)-w^{rc}_{1,0}(D,T) & w^{rc}_0\left(D,T,X;g\right) &=w^{rc}_{0,1}\left(D,T,X;g\right) - w^{rc}_{0,0}\left(D,T,X;g\right) 
    \end{align*}
    and for $t=0,1$
    \begin{align*}
        w^{rc}_{1,t}\left(D,T\right) &= \frac{D\cdot 1\left\{T=t\right\}}{\mathbb{E} \left[D\cdot 1\left\{T=t\right\}\right]}\\
        w^{rc}_{0,t}\left(D,T,X;g\right) &= \frac{g(X)\left(1-D\right)\cdot 1\left\{T=t\right\}}{1-g(X)} \left(\mathbb{E}\left[\frac{g(X)\left(1-D\right)\cdot 1\left\{T=t\right\}}{1-g(X)}\right]\right)^{-1}
    \end{align*}
\end{itemize}
Then if at least 
\begin{itemize}
    \item for \textbf{panel} data, either $\pi(X)\overset{a.s.}{=} p(X)$ or $\mu^p_{\Delta}(X) \overset{a.s.}{=} m^p_{0,1}(X)-m^p_{0,0}(X)$
    \item for \textbf{repeated cross-section} data, either $\pi(X)\overset{a.s.}{=} p(X)$ or $\mu^p_{0,\Delta}(X) \overset{a.s.}{=} m^{rc}_{0,1}(X)-m^{rc}_{0,0}(X)$\footnote{For repeated cross-section data, $\tau^{dr,rc}_1$ does not reply on OR models for the treated group but $\tau_2^{dr,rc}$ does, however, $\tau^{dr,rc}_1$ is not more robust against model misspecification than $\tau_2^{dr,rc}$ since they identify the ATT under the same conditions. Given that $\mathbb{E}\left[g(X)\mid D=1\right] = \mathbb{E}\left[g(X)\mid D=1,T=t\right],t=0,1$ holds for any $g(\cdot)$, it must hold for $\mu^{rc}_{1,t}(\cdot)-\mu^{rc}_{0,t}(\cdot),t=0,1$, even when $\mu^{rc}_{d,t}(\cdot)$ are misspecified.} 
\end{itemize}
that is, at least one of the working nuisance models is correctly specified, the ATT can be estimated. This is less demanding than both OR and IPW approach.

\paragraph*{Semiparametric efficiency bound} 
Let $m^p_{0,\Delta} \equiv m^p_{0,1}(x)-m^p_{0,0}(x)$ and $m^{rc}_{d,\Delta}(X)\equiv m^{rc}_{0,1}(X)-m^{rc}_{0,0}(X)$ for $d=0,1$. Then 
\begin{itemize}
    \item for \textbf{panel} data, the \textbf{efficient influence function} for the ATT is
    \begin{align*}
        \eta^{e,p}\left(Y_1,Y_0,D,X\right) =& w^p_1(D)\left(m^p_{1,\Delta}(X) - m^p_{0,\Delta}(X) -\tau \right) \\
        &+ w_1^p(D)\left(\Delta Y-m^p_{1,\Delta}(X)\right) - w^p_0(D,X;p)\left(\Delta Y-m^p_{0,\Delta}(X)\right)
    \end{align*}
    and the \textbf{semiparametric efficiency bound} for all regular ATT estimators is
    \begin{align*}
        \mathbb{E}\left[\eta^{e,p}\left(Y_1,Y_0,D,X\right)\right]^2 =& \frac{1}{\mathbb{E}\left[D\right]^2} \left[ D\left(m^p_{1,\Delta}(X)-m^p_{0,\Delta}(X)-\tau\right)^2 \right. \\
        & \left. + D\left(\Delta-m^p_{1,\Delta}(X)\right)^2 + \frac{(1-D)p(X)^2}{\left(1-p(X)\right)^2} \left(\Delta Y-m^p_{0,\Delta}(X)\right)^2 \right]
    \end{align*}
    \item for \textbf{repeated cross-section} data, the \textbf{efficient influence function} for the ATT is
    \begin{align*}
        \eta^{e,p}\left(Y_1,Y_0,D,X\right) =& \frac{D}{\mathbb{E}[D]}\left(m^{rc}_{1,\Delta}(X)-m^{rc}_{0,\Delta}(X)-\tau\right) \\
        &+\left( w^{rc}_{1,1}(D,T)\left(Y-m^{rc}_{1,1}(X)\right)-w^{rc}_{1,0}(D,T)\left(Y-m^{rc}_{1,0}(X)\right) \right)\\
        &- 
    \end{align*}
\end{itemize}

\newpage
\bibliographystyle{plainnat}
\bibliography{ref.bib}

\end{document}