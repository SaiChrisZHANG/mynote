\documentclass[twoside]{article}
\input{settings.tex}

\begin{document}
\lecture{16}{Graphical Network Inference}{}{Sai Zhang}{}{The note is built on Prof. \hyperlink{http://faculty.marshall.usc.edu/jinchi-lv/}{Jinchi Lv}'s lectures of the course at USC, DSO 607, High-Dimensional Statistics and Big Data Problems.}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

\section{Motivation}
Consider a classic question: Suppose we have $N$ observations of dimension $p$ follow $\mathcal{N}(\mu,\Sigma)$. let $\Theta = \Sigma^{-1}$, and $\mathbf{S}$ be the empirical covariance matrix. How can we capture the statistical relationships between the variables of interest? Write this question in matrix form:
\begin{example}{Multivariate Gaussian Distribution}{}
     $\mathbf{x}\sim \mathcal{N}(\mathbf{0},\boldsymbol{\Sigma})$ with the probability density 
    $$
    f(\mathbf{x}) = \frac{1}{(2\pi)^{p/2}\det (\boldsymbol{\Sigma})^{1/2}}\exp\left\{ -\frac{1}{2}\mathbf{x}'\boldsymbol{\Sigma}^{-1}\mathbf{x} \right\} \propto \det (\boldsymbol{\Theta})^{1/2}\exp\left\{ -\frac{1}{2} \mathbf{x}'\boldsymbol{\Theta}\mathbf{x} \right\}
    $$
    where $\boldsymbol{\Sigma}=\mathbb{E}[\mathbf{xx}'] > \mathbf{0}$ is the covariance matrix, and $ \boldsymbol{\Theta}=\boldsymbol{\Sigma}^{-1} $ is the \textbf{inverse covariance matrix} or \textbf{precision matrix}
\end{example}

%\newpage
%\bibliographystyle{plainnat}
%\bibliography{ref.bib}

\end{document}