\documentclass[twoside]{article}
\input{settings.tex}

\begin{document}
\lecture{20}{Random Forest}{}{Sai Zhang}{.}{The note is built on Prof. \hyperlink{http://faculty.marshall.usc.edu/jinchi-lv/}{Jinchi Lv}'s lectures of the course at USC, DSO 607, High-Dimensional Statistics and Big Data Problems.}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

\section{Motivation}
Denote by $m(\mathbf{X})$ the measurable nonparametric regression function with p-dimensional random vector $\mathbf{X}$ taking values in $[0,1]^p$. The Random Forest algorithm aims to learn the 
regression function in a non-parametric way based on the observations $\mathbf{x}_i \in [0,1]^p,y_i\in\mathbb{R},i=1,\cdots,n$, from the model 
$$
y_i = m(\mathbf{x}_i) + \epsilon_i
$$
where $\mathbf{X},\mathbf{x}_i,\epsilon_i,i=1,\cdots,n$ are independent, and $\left\{\mathbf{x}_i\right\}$ and $\left\{\epsilon_i\right\}$ are two sequences of identically distributed random variables. $\mathbf{x}_i$ is distributed identically as $\mathbf{X}$.

\paragraph*{Why Random Forest (RF)?} \textbf{RF} has gained 

\citet{chi2022asymptotic}

\newpage
\bibliographystyle{plainnat}
\bibliography{ref.bib}

\end{document}